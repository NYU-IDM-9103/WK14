{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WK14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP: Word2Vec\n",
    "\n",
    "### One-Hot Encoding + Classification = Embedding\n",
    "\n",
    "- Train network on a task that helps it encode information about the relationships of your data\n",
    "- In the end we throw away the last layers and just use the encoded information for other purposes\n",
    "\n",
    "It's like a more complex and rich form of finding covariances, where we end up with an abstract representation of the data. With text, we can train a network to predict words in a sequence, and then use the embeddings to perform search, similarity comparisons, generation, completion, visualizations, and other tasks.\n",
    "\n",
    "#### Code:\n",
    "- https://medium.com/@patrykmwieczorek/mastering-nlp-with-pytorch-word2vec-60a54030c720\n",
    "\n",
    "#### Explanation:\n",
    "- https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/DM-GY-9103-2024F-H/WK14/raw/main/WK14_utils.py\n",
    "\n",
    "!wget -q -P ./data/text https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/datasets/text/dickinson.txt\n",
    "!wget -qO- https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/datasets/text/rappers.tar.gz | tar xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from WK14_utils import TextUtils, TextSequenceDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SkipGram\n",
    "\n",
    "This network creates embeddings by learning to predict a set of words related to a target word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramDataset(TextSequenceDataset):\n",
    "  def __init__(self, text, max_words=200_000, window=2, symmetric_context=True):\n",
    "    super().__init__(text, max_words, window, symmetric_context)\n",
    "    self.X, self.Y = self.create_dataset(self.words, self.wtoi, self.window, self.symmetric_context)\n",
    "    assert len(self.X) == len(self.Y)\n",
    "\n",
    "  def create_dataset(self, words, wtoi, window, symmetric_context):\n",
    "    stopwords = TextUtils.stopwords + [\"=\", \":\", \",\", \"(\", \")\", \"{\", \"}\", \"[\", \"]\"]\n",
    "    xs, ys = [], []\n",
    "\n",
    "    for i in range(0, len(words)):\n",
    "      minj = i - window if symmetric_context else i + 1\n",
    "      maxj = i + window\n",
    "      if words[i] in stopwords:\n",
    "        continue\n",
    "      center_word = wtoi[words[i].lower()]\n",
    "      for j in range(minj, maxj + 1):\n",
    "        if j == i or j < 0 or j > len(words) - 1 or words[j] in stopwords:\n",
    "          continue\n",
    "        context_word = wtoi[words[j].lower()]\n",
    "        xs.append(center_word)\n",
    "        ys.append(context_word)\n",
    "    return Tensor(xs).long().to(self.device), Tensor(ys).long().to(self.device)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    if type(idx) is slice:\n",
    "      return list(zip(self.X[idx], self.Y[idx]))\n",
    "    return (self.X[idx], self.Y[idx])\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/text/dickinson.txt\", \"r\") as f:\n",
    "  dickinson_text = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df = pd.read_csv(\"./data/text/rappers.csv\")\n",
    "rapper_text = lyrics_df[\"lyric\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SkipGramDataset(text=dickinson_text, max_words=500_000, window=3, symmetric_context=False)\n",
    "train_dl = DataLoader(dataset, batch_size=4096, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "  def __init__(self, vocab_size, embed_dim=128):\n",
    "    super().__init__()\n",
    "    self.center_embeds = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n",
    "    self.context_embeds = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    center_word = self.center_embeds(x)\n",
    "    scores = torch.matmul(center_word, self.context_embeds.weight.t())\n",
    "    return scores\n",
    "\n",
    "  def get_embedding(self, x):\n",
    "    return self.center_embeds(x)\n",
    "\n",
    "  def get_N_closest(self, x_emb, N=5, metric=\"lnorm\"):\n",
    "    # calculate similarity between x and all other embeddings\n",
    "    if metric == \"sine\":\n",
    "      cos_sim = nn.CosineSimilarity()\n",
    "      similarities = cos_sim(x_emb, self.center_embeds.weight).squeeze()\n",
    "      largest = True\n",
    "    elif metric == \"lnorm\":\n",
    "      similarities = torch.cdist(x_emb, self.center_embeds.weight).squeeze()\n",
    "      largest = False\n",
    "    return torch.topk(similarities, k=N, largest=largest)\n",
    "\n",
    "  def get_N_closest_idx(self, x_idx, N=5, metric=\"lnorm\"):\n",
    "    # get word embedding\n",
    "    x_emb = self.get_embedding(x_idx)\n",
    "\n",
    "    # use embedding distances to return top-N similar word_idxs\n",
    "    values, indices = self.get_N_closest(x_emb, N=N, metric=metric)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = SkipGram(vocab_size=len(dataset.wtoi), embed_dim=64).to(mdevice)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "ctr,ctx = next(iter(train_dl))\n",
    "print(ctr.shape, ctx.shape)\n",
    "\n",
    "ctx_pred = model(ctr)\n",
    "print(ctx_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(32):\n",
    "  model.train()\n",
    "  for center, context in train_dl:\n",
    "    optim.zero_grad()\n",
    "    context_pred = model(center)\n",
    "    loss = loss_fn(context_pred, context)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "  if e % 4 == 3:\n",
    "    print(f\"Epoch: {e} loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = dataset.encode_word(\"wild\", return_tensors=True)\n",
    "\n",
    "top5s = model.get_N_closest_idx(query, N=5, metric=\"sine\")\n",
    "top5l = model.get_N_closest_idx(query, N=5, metric=\"lnorm\")\n",
    "\n",
    "print(dataset.decode(top5s))\n",
    "print(dataset.decode(top5l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "q = dataset.encode(['wild', 'swoon', 'medicine', 'austere', 'stays'])\n",
    "q_e = model.get_embedding(q)\n",
    "q_diff = q_e[1:, :] - q_e[:-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Next Steps\n",
    "\n",
    "- Implement a translator between two text corpus\n",
    "  - Get a phrase from one text: [W0, W1, W2, etc]\n",
    "  - Get list of embeddings and their relative distances/directions\n",
    "  - Find embedding of W0 in second dataset\n",
    "  - Follow the directions from first dataset, while moving around the second dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
